[עמודים 1-5]

- המחקר "THE DANGERS OF ARTIFICIAL INTELLIGENCE" מאת וליבור בוז'יץ', רופא בבית החולים הכללי בקופריבניצה, פורסם במאי 2023.
- המחקר עוסק בסיכונים והסכנות הטמונות בשימוש בבינה מלאכותית (AI), לצד הפוטנציאל החיובי שלה בתחומים כמו בריאות, חינוך, יעילות ופרודוקטיביות.
- הסיכונים המרכזיים של AI כוללים הטיה (bias), חוסר שקיפות, אבטלה, שימוש זדוני, תלות יתר, ועוד.
- הטיה ב-AI: מערכות AI עלולות להנציח ולהגביר הטיות חברתיות קיימות, למשל בהעסקה או במערכת המשפט, מה שעלול להוביל לאפליה בלתי הוגנת כלפי קבוצות מסוימות.
- חוסר שקיפות: לעיתים קשה להבין כיצד מערכות AI מקבלות החלטות, דבר שמוביל לחוסר אמון, במיוחד בתחומים קריטיים כמו בריאות ומשפט.
- אבטלה: אוטומציה של עבודות רבות על ידי AI עלולה לגרום לאובדן משרות, בעיקר בקרב עובדים בעלי מיומנויות נמוכות, ולהחריף פערים חברתיים.
- שימוש זדוני: AI יכול לשמש לפיתוח נשק אוטונומי, יצירת דיפייקים להפצת מידע שגוי, ולביצוע פשעים סייבר.
- תלות יתר: הסתמכות מופרזת על AI עלולה לפגוע ביכולת החשיבה הביקורתית והעצמאית של בני אדם, ולהפוך את החברה לפגיעה יותר.
- דרכי הפחתת הסיכונים כוללות רגולציה ופיקוח ממשלתי, פיתוח מסגרות אתיות, ביקורת ואחריות, פיתוח שיתופי בין אדם למכונה, והשקעה בחינוך והעלאת מודעות.
- דוגמאות לשימוש לא מבוקר ב-AI: טכנולוגיות זיהוי פנים עם הטיות, תאונות עם רכבים אוטונומיים (כמו תאונת אובר באריזונה ב-2018), שימוש ב-AI לאכיפת חוק עם הטיות, ומערכות סינון מועמדים לעבודה עם אפליה.
- כלים לשליטה בשימוש ב-AI כוללים פיתוח רגולציות וסטנדרטים, מסגרות אתיות, ביקורת על מערכות AI, פיתוח שיתופי עם בעלי עניין, וקמפיינים לחינוך והעלאת מודעות.
- המסקנה המרכזית היא שיש לאמץ גישה אחראית ואתית בפיתוח ובשימוש ב-AI כדי למקסם את היתרונות ולהפחית את הסיכונים, תוך שמירה על שקיפות, אחריות ושיתוף פעולה בין בני אדם למכונות.
- המחקר מתבסס על מקורות רבים, ביניהם מחקרים על הטיות ב-AI, דוחות עתיד התעסוקה, מסמכי מדיניות של האיחוד האירופי, ומאמרים על שימוש זדוני ב-AI.

הטקסט כולל סקירה מקיפה של הסכנות והפתרונות לשימוש בטכנולוגיית AI, אך חסר מידע על פרטים טכניים או דוגמאות נוספות מעבר לאלו שהוזכרו.